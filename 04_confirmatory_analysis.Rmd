---
title: "Gaze Following confirmatory Analysis"
author: "The Gaze Following Analysis Team"
date: '`r format(Sys.time(), "%a %b %d %X %Y")`'
output: 
  html_document:
    toc: true
    toc_float: true
    number_sections: yes
editor_options: 
  chunk_output_type: inline
---

# Intro

This RMarkdown file reports analyses of the primary Gaze Following dataset. It relies on data cached in `03_exclusions.Rmd`.

There are four datasets for MLM models

* d_first: direction of first look (congruent/incongruent) and latency of first shifts. Proportion difference score (c-i)/(c+i)
* d_freq: frequency of looks to congruent vs. incongruent. Proportion difference score (c-i)/(c+i)
* d_duration: fixation duration to congruent vs. incongruent. Proportion difference score (c-i)/(c+i) 
* d_latency: infants' reaction time

And their associated datasets for meta-analysis

* d_first_meta: direction of first look (congruent/incongruent) and latency of first shifts. Proportion difference score (c-i)/(c+i)
* d_freq_meta: frequency of looks to congruent vs. incongruent. Proportion difference score (c-i)/(c+i)
* d_duration_meta: fixation duration to congruent vs. incongruent. Proportion difference score (c-i)/(c+i)
* d_latency_meta: infants' reaction time

```{r setup, echo=FALSE, message=FALSE}
source("helper/common.R")
source("helper/ma_helper.R")
export_figs <- FALSE
```


```{r}

iv_columns <- c("lab", "subid", "trial_num", "age_group", "age_days", "participant_gender", "lang_group", "coding")
dv_columns <- c("first_shift", "latency", "n_shift_congruent", "n_shift_incongruent", "fixation_congruent", "fixation_incongruent")

d <- read_csv("processed_data/03_data_trial_main.csv") %>%
  select(iv_columns, dv_columns) %>%
  mutate_at(vars(lab,subid,age_group, participant_gender, lang_group, first_shift, coding), as.factor) %>%
  mutate_at(vars(age_group, lang_group), fct_rev)

```


Create datasets for analysis. Meta-analytic sets have mean by infant

```{r}

d_first <- d %>%
  filter(!is.na(first_shift)) %>% # Select only trials that had a shift
  select(-latency, -n_shift_congruent, -n_shift_incongruent, -fixation_congruent, - fixation_incongruent)

d_first_meta <- d_first %>%
  group_by_at(vars(-trial_num)) %>%
  summarise(n = n()) %>%
  spread(key = first_shift, value = n, fill = 0) %>%
  mutate(prop = (congruent-incongruent)/(congruent+incongruent)) %>% # Calculate proportion difference score
  select(-congruent, -incongruent) %>%
  filter(!is.na(prop)) %>%
  group_by(subid, age_group, lang_group, lab) %>%
  summarise(prop = mean(prop, na.rm = TRUE))

d_freq <- d %>%
  select(-first_shift, -latency, -fixation_congruent, - fixation_incongruent) %>%
  filter((n_shift_congruent + n_shift_incongruent) > 0) %>% # Select only trials that had a shift
  gather(key = "object", value = "n_shift", n_shift_congruent, n_shift_incongruent) %>%
  mutate(object = case_when(
    object == "n_shift_congruent" ~ "congruent",
    object == "n_shift_incongruent" ~ "incongruent"
  )) %>%
  mutate(object = as.factor(object))

d_freq_meta <- d  %>%
  group_by_at(vars(-trial_num)) %>%
  select(-first_shift, -latency, -fixation_congruent, - fixation_incongruent) %>%
  filter((n_shift_congruent + n_shift_incongruent) > 0) %>% # Select only trials that had a shift
  mutate(prop = (n_shift_congruent -  n_shift_incongruent)/(n_shift_congruent + n_shift_incongruent)) %>% # Calculate proportion difference score on each trial
  group_by_at(vars(-trial_num, - prop)) %>%
  mutate(prop = mean(prop)) %>% # Average proportion difference score by baby
  group_by(subid, age_group, lang_group, lab) %>%
  summarise(prop = mean(prop, na.rm = TRUE))
  
d_duration <- d %>%
  select(-first_shift, -latency, -n_shift_congruent, -n_shift_incongruent) %>%
  filter(fixation_congruent + fixation_incongruent > 0) %>% # Select only trials that had any looking
  gather(key = "object", value = "duration", fixation_congruent, fixation_incongruent) %>%
  mutate(object = case_when(
    object == "fixation_congruent" ~ "congruent",
    object == "fixation_incongruent" ~ "incongruent"
  )) %>%
  mutate(object = as.factor(object)) %>%
  mutate(duration = log(duration + 1)) # Log-transform duration scores, adding one to deal with zeros


d_duration_meta <- d %>%
  select(-first_shift, -latency, -n_shift_congruent, -n_shift_incongruent) %>%
  filter(fixation_congruent + fixation_incongruent > 0) %>%
  mutate(prop = (fixation_congruent - fixation_incongruent)/(fixation_congruent + fixation_incongruent)) %>% # Calculate proportion difference score
  group_by_at(vars(-trial_num, - prop)) %>%
  mutate(prop = mean(prop)) # Average proportion difference score by baby


d_latency <- d %>%
  select(-n_shift_congruent, -n_shift_incongruent, -fixation_congruent, - fixation_incongruent) %>%
  rename("object" = "first_shift") %>%
  filter(!is.na(object)) %>% # only trials with first shifts
  mutate(latency = log(latency + 1)) # Log transform latency scores, adding one to deal with zeros
  

d_latency_meta <- d %>%
  select(-n_shift_congruent, -n_shift_incongruent, -fixation_congruent, - fixation_incongruent) %>%
  rename("object" = "first_shift") %>%
  filter(!is.na(object)) %>%
  mutate(object = as.factor(object)) %>%
  group_by_at(vars(-trial_num, - latency)) %>%
  mutate(latency = mean(latency)) # Average proportion difference score by baby
  



```

# Dataset Descriptives

Plot of participants across age.

```{r}
participants <- d %>%
  group_by(lab, subid, lang_group) %>%
  summarise(age_days = age_days[1]) 

ggplot(participants, 
       aes(x = age_days/(365.25/12), fill = lab)) + 
  geom_histogram(binwidth = 1) + 
  facet_grid(.~lang_group) +
  ylab("Number of babies") + 
  xlab("Age (months)") + 
  xlim(3, 16) + 
  scale_fill_discrete(guide = FALSE)
```
Number of included babies from each lab. 

```{r}
d %>%
  group_by(lab, age_group, lang_group) %>%
  summarize(n = n_distinct(subid)) %>%
  spread(key = lang_group, value = n) %>%
  mutate(monolingual = replace_na(monolingual, 0),
         bilingual = replace_na(bilingual, 0)) %>% 
  kable()
```

Total babies: `r d %>% group_by(lab, subid) %>% summarise(n = n()) %>% nrow()`.

On how many trials do infants make a face-to-object saccade?

```{r}

d_latency %>%
  group_by(subid, age_group) %>%
  filter(!is.na(latency)) %>%
  summarize(n_trials = length(trial_num)) %>%
  ggplot(aes(x = n_trials)) +
  geom_histogram()


```

On how many trials do infants look at the target object?

```{r}

d %>%
  group_by(subid, age_group) %>%
  filter(!is.na(fixation_congruent)) %>%
  summarize(n_trials = length(trial_num)) %>%
  ggplot(aes(x = n_trials)) +
  geom_histogram()


```

What is the distribution of infants' first-look proportions?

```{r}

d_first_meta %>%
  group_by(subid, age_group, lang_group) %>%
  summarise(prop = mean(prop, na.rm = TRUE)) %>%
  ggplot(aes(x = prop, color = lang_group)) +
  facet_grid(lang_group~age_group) +
  geom_histogram()


```


# Pirate plots

## First look
```{r first look pirate}

d_first_meta %>%
  group_by(subid, age_group, lang_group) %>%
  summarise(prop = mean(prop, na.rm = TRUE)) %>%
  pirateplot(formula = prop ~ lang_group + age_group, data = ., main = "First look proportion", theme = 1, bar.f.o = .5, bean.f.o = 0, bar.b.col = 1, bar.lwd = .5, bean.b.col = 1, inf.f.o = 0, inf.method = "se")

```
#Same graph created with ggplot
```{r first look ggplot}
d_first_meta %>% 
  group_by(subid, age_group, lang_group) %>% 
  summarise(prop = mean(prop, na.rm = TRUE)) %>% 
  ggplot(aes(x = age_group, y = prop)) + 
  geom_violin(aes(colour = lang_group), alpha = .5) +
  # geom_dotplot(binaxis = "y", stackdir = "center", position = position_dodge(width = 0.9), 
  #              dotsize = .6, alpha = 0.4, aes(fill = lang_group)) +
  geom_point(aes(x = age_group, color= lang_group), line = "black", alpha = .3, position = position_jitterdodge()) +
  stat_summary(fun.y = "mean", geom = "bar", color = "black", aes(fill = lang_group), 
               alpha = .4, position = position_dodge(width = 0.9)) + 
  stat_summary(fun.data = mean_se, geom = "errorbar", width = .5,  aes(group = lang_group), 
               position = position_dodge(width = 0.9)) +
  geom_abline(intercept = 0, lty = 3, slope = 0) +
  ylab("Difference score") +
  xlab("Age Group") +
  scale_colour_manual(name = "Language group", values = c("darkcyan", "darkred")) +
  scale_fill_manual(name = "Language group", values = c("darkcyan", "darkred")) + 
  theme(text = element_text(size = 20), legend.position = "bottom")
```

## Frequency
```{r frequenct pirate}

pirateplot(formula = prop ~ lang_group + age_group, data = d_freq_meta, main = "Frequency proportion", theme = 1, bar.f.o = .5, bean.f.o = 0, bar.b.col = 1, bar.lwd = .5, bean.b.col = 1, inf.f.o = 0, inf.method = "se")

```
#Same graph created with ggplot
```{r frequency ggplot}
d_freq_meta %>% 
  group_by(subid, age_group, lang_group) %>% 
  summarise(prop = mean(prop, na.rm = TRUE)) %>% 
  ggplot(aes(x = age_group, y = prop)) + 
  geom_violin(aes(colour = lang_group), alpha = .5) +
  # geom_dotplot(binaxis = "y", stackdir = "center", position = position_dodge(width = 0.9), 
  #              dotsize = .6, alpha = 0.4, aes(fill = lang_group)) +
  geom_point(aes(x = age_group, color= lang_group), line = "black", alpha = .3, position = position_jitterdodge()) +
  stat_summary(fun.y = "mean", geom = "bar", color = "black", aes(fill = lang_group), 
               alpha = .4, position = position_dodge(width = 0.9)) + 
  stat_summary(fun.data = mean_se, geom = "errorbar", width = .5,  aes(group = lang_group), 
               position = position_dodge(width = 0.9)) +
  geom_abline(intercept = 0, lty = 3, slope = 0) +
  ylab("Difference score") +
  xlab("Age Group") +
  scale_colour_manual(name = "Language group", values = c("darkcyan", "darkred")) +
  scale_fill_manual(name = "Language group", values = c("darkcyan", "darkred")) + 
  theme(text = element_text(size = 20), legend.position = "bottom")
```

## Duration
```{r duration pirate}
d_duration_meta %>%
  group_by(subid, age_group, lang_group) %>%
  summarise(prop = mean(prop, na.rm = TRUE)) %>%
pirateplot(formula = prop ~ lang_group + age_group, data = d_duration_meta, main = "Fixation duration proportion", theme = 1, bar.f.o = .5, bean.f.o = 0, bar.b.col = 1, bar.lwd = .5, bean.b.col = 1, inf.f.o = 0, inf.method = "se")

```
#Same graph created with ggplot
```{r duration ggplot}
d_duration_meta %>% 
  group_by(subid, age_group, lang_group) %>% 
  summarise(prop = mean(prop, na.rm = TRUE)) %>% 
  ggplot(aes(x = age_group, y = prop)) + 
  geom_violin(aes(colour = lang_group), alpha = .5) +
  # geom_dotplot(binaxis = "y", stackdir = "center", position = position_dodge(width = 0.9), 
  #              dotsize = .6, alpha = 0.4, aes(fill = lang_group)) +
  geom_point(aes(x = age_group, color= lang_group), line = "black", alpha = .3, position = position_jitterdodge()) +
  stat_summary(fun.y = "mean", geom = "bar", color = "black", aes(fill = lang_group), 
               alpha = .4, position = position_dodge(width = 0.9)) + 
  stat_summary(fun.data = mean_se, geom = "errorbar", width = .5,  aes(group = lang_group), 
               position = position_dodge(width = 0.9)) +
  geom_abline(intercept = 0, lty = 3, slope = 0) +
  ylab("Difference score") +
  xlab("Age Group") +
  scale_colour_manual(name = "Language group", values = c("darkcyan", "darkred")) +
  scale_fill_manual(name = "Language group", values = c("darkcyan", "darkred")) + 
  theme(text = element_text(size = 20), legend.position = "bottom")
```

## Latency
```{r latency pirate}
d_latency_meta %>% 
  filter(object == "congruent") %>%
  group_by(subid, age_group, lang_group) %>% 
  summarise(latency = mean(latency, na.rm = TRUE)) %>% 
    group_by(subid, age_group, lang_group) %>% 
pirateplot(formula = latency ~ lang_group + age_group, data = d_latency_meta, main = "Latency", theme = 6, pal = "southpark", cex.names = .5)

```
#Same graph created with ggplot
```{r latency ggplot}
d_latency_meta %>% 
  filter(object == "congruent") %>%
  group_by(subid, age_group, lang_group) %>% 
  summarise(latency = mean(latency, na.rm = TRUE)) %>% 
    group_by(subid, age_group, lang_group) %>% 
  ggplot(aes(x = age_group, y = latency)) + 
  geom_violin(aes(colour = lang_group), alpha = .5) +
  # geom_dotplot(binaxis = "y", stackdir = "center", position = position_dodge(width = 0.9), 
  #              dotsize = .6, alpha = 0.4, aes(fill = lang_group)) +
  geom_point(aes(x = age_group, color= lang_group), line = "black", alpha = .3, position = position_jitterdodge()) +
  stat_summary(fun.y = "mean", geom = "bar", color = "black", aes(fill = lang_group), 
               alpha = .4, position = position_dodge(width = 0.9)) + 
  stat_summary(fun.data = mean_se, geom = "errorbar", width = .5,  aes(group = lang_group), 
               position = position_dodge(width = 0.9)) +
  geom_abline(intercept = 0, lty = 3, slope = 0) +
  ylab("Latency (ms)") +
  xlab("Age Group") +
  scale_colour_manual(name = "Language group", values = c("darkcyan", "darkred")) +
  scale_fill_manual(name = "Language group", values = c("darkcyan", "darkred")) + 
  theme(text = element_text(size = 20), legend.position = "bottom")
```


# Meta-analytic framework

## First-look means
```{r}
d_first_meta %>%
  group_by(age_group, lang_group) %>%
  summarise(sd_norm = sd(prop), prop = mean(prop), sd_prop = sqrt(prop*(1-prop))) %>% #
  select(age_group, lang_group, prop, sd_prop, sd_norm)
```

```{r first meta data}
d_z_first <- d_first_meta %>%
  group_by(subid, lab, age_group, lang_group) %>%
  summarise(mean_prop = mean(prop, na.rm = TRUE)) %>%
  group_by(lab, age_group, lang_group) %>%
  summarise(d = mean(mean_prop, na.rm = TRUE) / sd(mean_prop, na.rm = TRUE), 
            n = length(unique(subid)), 
            d_var = d_var_calc(n, d)) %>%
 filter(n >= 10) #Filtering out subgroups with fewer than 10 babies
```

## First look model with language and age

```{r first meta}
first_meta <- metafor::rma(d ~ lang_group * age_group, vi = d_var, 
                    slab = lab, data = d_z_first, method = "REML") 
summary(first_meta)
```

## Frequency means
```{r}
d_freq_meta %>%
  group_by(age_group, lang_group) %>%
  summarise(sd = sd(prop, na.rm = TRUE), prop = mean(prop, na.rm = TRUE)) %>%
  select(age_group, lang_group, prop, sd)
```

What is the distribution of infants' first-look proportions?

```{r}

d_freq_meta %>%
  ggplot(aes(x = prop, color = lang_group)) +
  facet_grid(lang_group~age_group) +
  geom_histogram()
```

```{r frequency meta data}
d_z_freq <- d_freq_meta %>%
  group_by(lab, age_group, lang_group) %>%
  summarise(d = mean(prop, na.rm = TRUE) / sd(prop, na.rm = TRUE), 
            n = length(unique(subid)), 
            d_var = d_var_calc(n, d)) %>%
  filter(n >= 10) #Filtering out subgroups with fewer than 10 babies
```

```{r frequency meta}
freq_meta <- metafor::rma(d ~ lang_group * age_group, vi = d_var, 
                    slab = lab, data = d_z_freq, method = "REML") 
summary(freq_meta)
```

## Duration means
```{r}
d_duration_meta %>%
  group_by(age_group, lang_group) %>%
  summarise(sd = sd(prop, na.rm = TRUE), prop = mean(prop, na.rm = TRUE)) %>%
  select(age_group, lang_group, prop, sd)
```

```{r duration meta data}
d_z_dur <- d_duration_meta %>%
  group_by(lab, age_group, lang_group) %>%
  summarise(d = mean(prop, na.rm = TRUE) / sd(prop, na.rm = TRUE), 
            n = length(unique(subid)), 
            d_var = d_var_calc(n, d)) %>%
  filter(n >= 10) #Filtering out subgroups with fewer than 10 babies
```

```{r duration meta}
dur_meta <- metafor::rma(d ~ lang_group * age_group, vi = d_var, 
                    slab = lab, data = d_z_dur, method = "REML") 
summary(dur_meta)
```

## Latency means
```{r}
d_latency_meta %>%
  filter(object != "incongruent")%>% # Select only trials that are congruent
  group_by(age_group, lang_group) %>%
  summarise(sd = sd(latency, na.rm = TRUE), latency = mean(latency, na.rm = TRUE)) %>%
  select(age_group, lang_group, latency, sd)
```

```{r latency meta data}
d_z_latency <- d_latency_meta %>%
  filter(object != "incongruent")%>% # Select only trials that are congruent
  group_by(lab, age_group, lang_group, subid) %>% 
  summarise(latency = mean(latency))%>%
  group_by(lab, age_group, lang_group) %>% 
  summarise(d = mean(latency) / sd(latency),
            n = length(unique(subid)),
            d_var = d_var_calc(n,d))%>%
  filter(n>=10) #Filtering out subgroups with fewer than 10 babies

```{r latency meta}
Latency_meta <- metafor::rma(d ~ lang_group * age_group, vi = d_var, 
                    slab = lab, data = d_z_latency, method = "REML") 
summary(Latency_meta)
```


#MLM framework

## First_look MLM

```{r}
##The preregistered model: But get "singular fit" & "failure to converge" error message
#first_glmer <- d_first %>% 
#  mutate(age_days = scale(age_days, scale = FALSE)) %>%
#  filter(!is.na(first_shift)) %>%
#  mutate(first_shift = fct_rev(first_shift)) %>% # So higher numbers mean more looks to congruent
#  glmer(first_shift ~ lang_group*age_days + (1|subid) + (lang_group*age_days|lab) + (lang_group*age_days|trial_num),
#  data = .,
#  family = binomial
#)

##Simplifying the random effects: But "Model failed to converge with max|grad|" & "Model is nearly unidentifiable: very large eigenvalue - Rescale variables?" error messages
#first_glmer <- d_first %>% 
#  mutate(age_days = scale(age_days, scale = FALSE)) %>%
#  filter(!is.na(first_shift)) %>%
#  mutate(first_shift = fct_rev(first_shift)) %>% # So higher numbers mean more looks to congruent
#  glmer(first_shift ~ lang_group * age_days + (1|subid) + (1|lab) + (1|trial_num),
#  data = .,
#  family = binomial 
#)

##Changing the default control optimizer to "bobyqa" & rescaling "age_days" variable (scale = TRUE) to solve the convergence issues: But "singular fit" error message again
#first_glmer <- d_first %>% 
#  mutate(age_days = scale(age_days, scale = TRUE)) %>%
#  filter(!is.na(first_shift)) %>%
#  mutate(first_shift = fct_rev(first_shift)) %>% # So higher numbers mean more looks to congruent
#  glmer(first_shift ~ lang_group * age_days + (1|subid) + (1|lab) + (1|trial_num),
#  data = .,
#  control=glmerControl(optimizer="bobyqa"),
#  family = binomial 
#)

##Final model: Dropping the "trial_num" random effect as "trial_num" has 0 variance
first_glmer <- d_first %>% 
  mutate(age_days = scale(age_days, scale = TRUE)) %>%
  filter(!is.na(first_shift)) %>%
  mutate(first_shift = fct_rev(first_shift)) %>% # So higher numbers mean more looks to congruent
  glmer(first_shift ~ lang_group * age_days + (1|subid) + (1|lab),
  data = .,
  family = binomial 
)

summary(first_glmer)

```

## Frequency LMEM

```{r}
##The preregistered model: But get "singular fit" error message
#freq_lmer <- d_freq %>% 
#  mutate(age_days = scale(age_days, scale = FALSE)) %>%
#  mutate(object_bin = (as.integer(fct_rev(object)) - 1)) %>% # Recode to binary: congruent = 1, incongruent = 0
#  lmer(n_shift ~ lang_group*age_days*object+ (object|subid) + (lang_group*object|lab) + (lang_group*object|trial_num),
#  data = .
#)

##Simplifying the random effects: But "singular fit" again
#freq_lmer <- d_freq %>%
#  mutate(age_days = scale(age_days, scale = FALSE)) %>%
#  mutate(object_bin = (as.integer(fct_rev(object)) - 1)) %>% # Recode to binary: congruent = 1, incongruent = 0
#  lmer(n_shift ~ lang_group*age_days*object+ (1|subid) + (1|lab) + (1|trial_num),
#  data = .
#)

##Dropping the "lab" random effect as "lab" has 0 variance: But get "model failed to converge" error message
#freq_lmer <- d_freq %>%
#  mutate(age_days = scale(age_days, scale = FALSE)) %>%
#  mutate(object_bin = (as.integer(fct_rev(object)) - 1)) %>% # Recode to binary: congruent = 1, incongruent = 0
#  lmer(n_shift ~ lang_group*age_days*object+ (1|subid) + (1|trial_num),
#  data = .
#)

##Final model: Changing the default control optimizer to "bobyqa" to solve the convergence issue
freq_lmer <- d_freq %>% 
  mutate(age_days = scale(age_days, scale = FALSE)) %>%
  mutate(object_bin = (as.integer(fct_rev(object)) - 1)) %>% # Recode to binary: congruent = 1, incongruent = 0
  lmer(n_shift ~ lang_group*age_days*object + (1|subid) + (1|trial_num), control = lmerControl("bobyqa"),
  data = .
 )

summary(freq_lmer)

```

## Freq_look visualization

```{r}
d_freq %>% 
  group_by(age_group, lang_group) %>%
 # summarize(prop = mean(prop, na.rm = TRUE), sd = sd(prop, na.rm = TRUE)) %>%
  ggplot(aes(x = lang_group, y = n_shift, color = lang_group)) +
  geom_boxplot() +
  geom_jitter() +
  facet_grid(.~age_group)  



```


# Duration LMEM

```{r}
##The preregistered model: But get "singular fit" error message
#duration_lmer <- d_duration %>% 
#  mutate(age_days = scale(age_days, scale = FALSE)) %>%
#  mutate(object_bin = (as.integer(fct_rev(object)) - 1)) %>% # Recode to binary: congruent = 1, incongruent = 0
#  lmer(duration ~ lang_group*age_days*object+ (object|subid) + (lang_group*object|lab) + (lang_group*object|trial_num),
#  data = .
#)

##Simplifying the random effects: But "singular fit" again
#duration_lmer <- d_duration %>% 
#  mutate(age_days = scale(age_days, scale = FALSE)) %>%
#  mutate(object_bin = (as.integer(fct_rev(object)) - 1)) %>% # Recode to binary: congruent = 1, incongruent = #0
#  lmer(duration ~ lang_group*age_days*object+ (1|subid) + (1|trial_num) + (1|lab),
#  data = .
#)

##Final model: Dropping the "subid" random effect as "subid" has 0 variance
duration_lmer <- d_duration %>% 
  mutate(age_days = scale(age_days, scale = FALSE)) %>%
  mutate(object_bin = (as.integer(fct_rev(object)) - 1)) %>% # Recode to binary: congruent = 1, incongruent = 0
  lmer(duration ~ lang_group*age_days*object + (1|trial_num) + (1|lab),
  data = .
)

summary(duration_lmer)



```

## Visualize duration

```{r}

d_duration %>%
 # group_by(age_group, lang_group, object) %>%
 # summarize(duration = mean(duration)) %>%
  ggplot(aes(y = duration, x = object, color - lang_group)) +
  facet_grid(lang_group ~ age_group) +
  geom_violin() +
  geom_boxplot(width = .1)


```


## Latency LMEM

```{r}
##The preregistered model: Since we are looking only at "object = congruent", we have to remove the "object" effect from this model
#latency_lmer <- d_latency %>% 
#  mutate(age_days = scale(age_days, scale = FALSE)) %>%
#  mutate(object_bin = (as.integer(fct_rev(object)) - 1)) %>% # Recode to binary: congruent = 1, incongruent = 0
#  lmer(latency ~ lang_group*age_days*object+ (object|subid) + (lang_group*object|lab) + (lang_group*object|trial_num),
#  data = .
#)

##Dropping the "object" effect: But get "singular fit" error message
#latency_lmer <- d_latency %>% 
#  mutate(age_days = scale(age_days, scale = FALSE)) %>%
#  filter(object == "congruent") %>% # Select only trials that are congruent
#  lmer(latency ~ lang_group * age_days + (1|subid) + (lang_group|lab) + (lang_group|trial_num),
#  data = .
#)

##Final model: Simplifying the random effects
latency_lmer <- d_latency %>% 
  mutate(age_days = scale(age_days, scale = FALSE)) %>%
  filter(object == "congruent") %>% # Select only trials that are congruent
  lmer(latency ~ lang_group * age_days + (1|subid) + (1|lab) + (1|trial_num),
  data = .
)

summary(latency_lmer)



```
